{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Fine-tune on High Quality Dataset\n",
                "\n",
                "This notebook demonstrates how to:\n",
                "1.  Process a new raw MIDI dataset using the existing tokenizer.\n",
                "2.  Load a pretrained model.\n",
                "3.  Fine-tune the model on the new dataset."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import torch\n",
                "from pathlib import Path\n",
                "from miditok import REMI\n",
                "from trainer import DecoderOnlyTransformer, Trainer, get_optimizer, get_scheduler, get_dataloaders\n",
                "\n",
                "# Ensure we are in the right directory\n",
                "# os.chdir('c:\\\\Users\\\\mayda\\\\Desktop\\\\music-autocomplete') # Uncomment if needed"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Configuration\n",
                "\n",
                "class Config:\n",
                "    # --- New Data Settings ---\n",
                "    raw_data_dir = \"hq_dataset_raw\"       # Folder containing your new .mid files\n",
                "    processed_data_dir = \"hq_dataset_processed\" # Folder to save tokenized .json files\n",
                "    tokenizer_file = \"lmd_matched_tokenizer.json\" # Use the SAME tokenizer as pretrained model\n",
                "    \n",
                "    # --- Fine-tuning Settings ---\n",
                "    pretrained_model_path = \"trained_models/full_run_v2/model.pt\"\n",
                "    run_name = \"finetune_hq_v1\"\n",
                "    \n",
                "    # --- Training Hyperparameters ---\n",
                "    # Usually lower LR for fine-tuning\n",
                "    learning_rate = 1e-5 \n",
                "    max_epochs = 10\n",
                "    batch_size = 16\n",
                "    \n",
                "    # --- Model Architecture (MUST MATCH PRETRAINED MODEL) ---\n",
                "    vocab_size = 5000\n",
                "    block_size = 1024\n",
                "    n_embed = 512\n",
                "    n_head = 8\n",
                "    n_blocks = 8\n",
                "    dropout = 0.1\n",
                "    \n",
                "    # --- Other Settings ---\n",
                "    num_songs = 1000 # Number of songs to use from the new dataset\n",
                "    val_split = 0.1\n",
                "    optimizer_type = 'adamw'\n",
                "    weight_decay = 0.01\n",
                "    adam_beta1 = 0.9\n",
                "    adam_beta2 = 0.95\n",
                "    momentum = 0.9\n",
                "    grad_clip = 1.0\n",
                "    scheduler = 'cosine'\n",
                "    min_learning_rate = 1e-6\n",
                "    lr_step_size = 10\n",
                "    lr_gamma = 0.1\n",
                "    lr_patience = 3\n",
                "    checkpoint_path = f'trained_models/{run_name}/model.pt'\n",
                "    load_checkpoint = False # We handle loading manually\n",
                "    compile = False\n",
                "    \n",
                "    # Helper to map 'tokenized_dir' for get_dataloaders compatibility\n",
                "    @property\n",
                "    def tokenized_dir(self):\n",
                "        return self.processed_data_dir\n",
                "\n",
                "config = Config()\n",
                "\n",
                "# Create output directories\n",
                "os.makedirs(config.processed_data_dir, exist_ok=True)\n",
                "os.makedirs(os.path.dirname(config.checkpoint_path), exist_ok=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Process Data (Tokenization)\n",
                "\n",
                "def process_data(config):\n",
                "    print(f\"Checking for new data in {config.raw_data_dir}...\")\n",
                "    raw_path = Path(config.raw_data_dir)\n",
                "    \n",
                "    if not raw_path.exists():\n",
                "        print(f\"WARNING: Raw data directory '{config.raw_data_dir}' does not exist.\")\n",
                "        print(\"Please create it and put your .mid files there.\")\n",
                "        return False\n",
                "        \n",
                "    midi_files = list(raw_path.rglob(\"*.mid\"))\n",
                "    if not midi_files:\n",
                "        print(f\"WARNING: No .mid files found in '{config.raw_data_dir}'.\")\n",
                "        return False\n",
                "        \n",
                "    print(f\"Found {len(midi_files)} MIDI files.\")\n",
                "    \n",
                "    # Load Tokenizer\n",
                "    if not os.path.exists(config.tokenizer_file):\n",
                "        print(f\"ERROR: Tokenizer file '{config.tokenizer_file}' not found.\")\n",
                "        return False\n",
                "        \n",
                "    print(f\"Loading tokenizer from {config.tokenizer_file}...\")\n",
                "    tokenizer = REMI(params=config.tokenizer_file)\n",
                "    \n",
                "    # Tokenize\n",
                "    print(f\"Tokenizing files to {config.processed_data_dir}...\")\n",
                "    tokenizer.tokenize_dataset(\n",
                "        files_paths=midi_files,\n",
                "        out_dir=config.processed_data_dir\n",
                "    )\n",
                "    print(\"Tokenization complete.\")\n",
                "    return True\n",
                "\n",
                "# Run processing\n",
                "# Note: If you have already processed the data, you can skip this or it will overwrite/add to existing files\n",
                "data_ready = process_data(config)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 2. Initialize Model and Load Pretrained Weights\n",
                "\n",
                "model = DecoderOnlyTransformer(\n",
                "    vocab_size=config.vocab_size,\n",
                "    n_embed=config.n_embed,\n",
                "    n_head=config.n_head,\n",
                "    n_blocks=config.n_blocks,\n",
                "    block_size=config.block_size,\n",
                "    dropout=config.dropout\n",
                ")\n",
                "\n",
                "print(f\"Model initialized.\")\n",
                "\n",
                "if os.path.exists(config.pretrained_model_path):\n",
                "    # Check for Git LFS pointer\n",
                "    if os.path.getsize(config.pretrained_model_path) < 1024:\n",
                "        print(f\"WARNING: Pretrained model file is very small. It might be a Git LFS pointer.\")\n",
                "        print(\"Please run 'git lfs pull' to download the actual weights.\")\n",
                "    else:\n",
                "        print(f\"Loading pretrained weights from {config.pretrained_model_path}...\")\n",
                "        try:\n",
                "            checkpoint = torch.load(config.pretrained_model_path, map_location='cpu')\n",
                "            model.load_state_dict(checkpoint['model_state_dict'])\n",
                "            print(\"Weights loaded successfully.\")\n",
                "        except Exception as e:\n",
                "            print(f\"Error loading weights: {e}\")\n",
                "else:\n",
                "    print(f\"WARNING: Pretrained model path {config.pretrained_model_path} does not exist.\")\n",
                "    print(\"Starting from scratch (random initialization).\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 3. Setup Training\n",
                "\n",
                "if data_ready or len(list(Path(config.processed_data_dir).glob(\"*.json\"))) > 0:\n",
                "    print(\"Loading DataLoaders...\")\n",
                "    train_loader, val_loader = get_dataloaders(config)\n",
                "    \n",
                "    total_steps = len(train_loader) * config.max_epochs\n",
                "    optimizer = get_optimizer(model, config)\n",
                "    scheduler = get_scheduler(optimizer, config, total_steps)\n",
                "\n",
                "    trainer = Trainer(\n",
                "        model=model,\n",
                "        optimizer=optimizer,\n",
                "        scheduler=scheduler,\n",
                "        train_loader=train_loader,\n",
                "        val_loader=val_loader,\n",
                "        config=config\n",
                "    )\n",
                "    \n",
                "    print(\"Starting Fine-tuning...\")\n",
                "    trainer.train()\n",
                "else:\n",
                "    print(\"No processed data found. Cannot start training.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}